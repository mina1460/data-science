{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdLV3_84qGf5"
      },
      "source": [
        "# Mina's Toolkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhy8fTcVqGgF"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qitYwL4OqGgG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import datascience\n",
        "import seaborn as sns \n",
        "import scipy.stats as stats\n",
        "import sklearn as sk\n",
        "from ast import literal_eval\n",
        "%matplotlib inline\n",
        "\n",
        "#suppress warnings\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtspeNzbqGgI"
      },
      "source": [
        "# Basic Dataframe operations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-fqr5JoqGgI"
      },
      "source": [
        "## Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VSMvtBqqGgJ"
      },
      "outputs": [],
      "source": [
        "#Mount Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r-b5h-SqGgK"
      },
      "source": [
        "## Loading a dataset from a csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDoq-pbnqGgK"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('path_to_df', sep=',')\n",
        "\n",
        "#you can change the separator to '\\t' if you want to use tab separated files\n",
        "\n",
        "df = pd.read_csv('path', sep='\\t')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynvLPNAqGgL"
      },
      "source": [
        "## Shape, describe, info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z06K7rYGqGgM"
      },
      "outputs": [],
      "source": [
        "X = 5\n",
        "df.head(X) #check the first X rows of the dataframe \n",
        "df.tail(X) #check the last X rows of the dataframe \n",
        "df.sample(X) #samples X rows of the dataframe randomly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxag1N8EqGgM"
      },
      "outputs": [],
      "source": [
        "df.shape\n",
        "df.describe()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bksllklIqGgN"
      },
      "source": [
        "add this line to change the appearance to be much nicer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0KzKrdxqGgN"
      },
      "outputs": [],
      "source": [
        "df.describe().style.background_gradient(cmap='Greens')\n",
        "#you can change the cmap to dozens of cmaps, check the online manual for them "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFpls21rqGgN"
      },
      "source": [
        "## Set a new index "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf0MC-04qGgO"
      },
      "outputs": [],
      "source": [
        "df.set_index('newIndex', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-KzAOB3qGgO"
      },
      "source": [
        "## Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxmJQiLeqGgO"
      },
      "source": [
        "check for duplicates by a specific column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNKp-11bqGgO"
      },
      "outputs": [],
      "source": [
        "df['colName'].duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhwM3snHqGgP"
      },
      "source": [
        "check for duplicates by a subset of columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOc-4oB5qGgP"
      },
      "outputs": [],
      "source": [
        "df.duplicated(subset=[colName1, colName2]).sum()\n",
        "\n",
        "#or\n",
        "\n",
        "cols = df.columns.tolist() #change to whatever subset you want, here I am checking for all columns \n",
        "df[cols].duplicated().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-_pi1CQqGgQ"
      },
      "source": [
        "### Dropping Duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AobjzSytqGgQ"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(subset=[colName1, colName2, etc], keep='first', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m41W_jcgqGgQ"
      },
      "source": [
        "## Value counts "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcIyr26pqGgQ"
      },
      "outputs": [],
      "source": [
        "#get value counts for a column \n",
        "df['colName'].value_counts()\n",
        "\n",
        "#don't drop nulls from it\n",
        "df['colName'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbvdaf8MqGgR"
      },
      "source": [
        "## Normalized Value counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emN3cGIeqGgR"
      },
      "outputs": [],
      "source": [
        "df['colName'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeHy7yl5qGgR"
      },
      "source": [
        "## getting numerical or categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoBxOYWIqGgR"
      },
      "outputs": [],
      "source": [
        "numerical_Cols = df.select_dtypes(include=['int64', 'float64']).columns.to_list()\n",
        "\n",
        "categoricalCols = df.select_dtypes(include=['object']).columns.to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2SotVozqGgS"
      },
      "source": [
        "## getting a list of columns in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hubpPUyFqGgS"
      },
      "outputs": [],
      "source": [
        "colsList = df.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4v_6af3qGgS"
      },
      "source": [
        "## Check for missing values in a Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZPoStKgqGgS"
      },
      "outputs": [],
      "source": [
        "#check for missing values sorted descendingly\n",
        "df.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyF7gQq6qGgT"
      },
      "source": [
        "## Fill missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2EllWPnqGgT"
      },
      "outputs": [],
      "source": [
        "#you can use .mean(), .mode(), or .median(), or even write a specific number here\n",
        "\n",
        "\n",
        "#inplace missing values replacement \n",
        "df['colName'].fillna(df['colName'].mean(), inplace=True)\n",
        "\n",
        "#or in a new column \n",
        "\n",
        "df['colNameNoMissing'] = df['colName'].fillna(df['colName'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRiVrpFbqGgT"
      },
      "source": [
        "## Dropping Missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyhS2yZgqGgU"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)\n",
        "\n",
        "#for a specific column\n",
        "df['colName'].dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVw8pUK2qGgU"
      },
      "source": [
        "## Dropping columns from a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrtySuDUqGgV"
      },
      "outputs": [],
      "source": [
        "newDf = df.drop(['colName'], axis=1)\n",
        "\n",
        "#or\n",
        "\n",
        "dropList = ['colName1', 'colName2']\n",
        "df.drop(dropList, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVbLtXStqGgV"
      },
      "source": [
        "## Drop row by its id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0Z-3fS5qGgV"
      },
      "outputs": [],
      "source": [
        "#drop a row by its id \n",
        "df.drop(1299, axis=0, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDUL1gAoqGgW"
      },
      "source": [
        "## Iterate over a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7u8m1a-qGgW"
      },
      "outputs": [],
      "source": [
        "for index, row in df.iterrows():\n",
        "    #access row by column name\n",
        "    if row['colName'] == 'value':\n",
        "        #do something\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMI-IhGNqGgW"
      },
      "outputs": [],
      "source": [
        "#loop over iteritems\n",
        "for colName, col in df.iteritems():\n",
        "    #access column by column name\n",
        "    if colName == 'colName':\n",
        "        #do something\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de1M25kYqGgX"
      },
      "outputs": [],
      "source": [
        "for (index, row) in df.iterrows():\n",
        "     if pd.isnull(row.loc['colName']): \n",
        "        df.loc[index, 'colName'] = 'replacemenetValue'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS5EyR-wqGgX"
      },
      "source": [
        "## Accessing a specific row "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntPo8vYXqGgX"
      },
      "outputs": [],
      "source": [
        "#this will modify any row whose colName value is equal to compareValue and set it to valuetoSet\n",
        "valuetoSet = 0\n",
        "compareValue = 5\n",
        "df.loc[df.loc[:, 'colName'] == compareValue , 'colName'] = valuetoSet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt3mFRuNqGgX"
      },
      "source": [
        "## Selecting rows by logical filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVDXZoGsqGgX"
      },
      "outputs": [],
      "source": [
        "selectedDf = df[df['colName'] == 'value']\n",
        "\n",
        "#combine two filters \n",
        "\n",
        "selectedDf = df[ df['colName'] == 'value' & df['colName2'] == 'value2']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7emJmyxqGgX"
      },
      "source": [
        "## Lambda functions on rows (better than loops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g58Ksu4PqGgX"
      },
      "outputs": [],
      "source": [
        "#apply a lambda function to a column\n",
        "\n",
        "df['LambdacolName'] = df['colName'].apply(lambda x: x + 1)\n",
        "\n",
        "#or you can call a function \n",
        "\n",
        "def function(X):\n",
        "    return X + 1\n",
        "\n",
        "\n",
        "modDfObj = df.apply(lambda x: np.square(x) if x.name == 'z' else x)\n",
        "\n",
        "df[\"LambdacolName\"] = df.apply(lambda x: function(x['colName']), axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ikcGrGEqGgY"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXQkhLfdqGgY"
      },
      "source": [
        "## Regression plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPC7PICLqGgY"
      },
      "outputs": [],
      "source": [
        "sns.regplot(x = 'col1', y = 'col2', data = df,scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZYbcQ8MqGgY"
      },
      "source": [
        "## Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y0Zr8VhqGgY"
      },
      "outputs": [],
      "source": [
        "df['colName'].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sh7LBZjqGgY"
      },
      "source": [
        "## Count plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55FQFmUSqGgZ"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=colName, data=df, hue='diff')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZKD9aQhqGgZ"
      },
      "source": [
        "## Annotating barplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44l5gXjZqGgZ"
      },
      "outputs": [],
      "source": [
        "for col in colsList: \n",
        "  fig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,6))  # 1 row, 2 columns\n",
        "  df[df['colName'] == 'Yes'][col].value_counts(normalize=True).plot(kind='bar', ax=ax1)\n",
        "  for p in ax1.patches:\n",
        "    ax1.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
        "\n",
        "  df[df['colName'] == 'No'][col].value_counts(normalize=True).plot(kind='bar', ax=ax2)\n",
        "  for p in ax2.patches:\n",
        "    ax2.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9IbU_rTqGgZ"
      },
      "source": [
        "## SNS barplots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6-M4WMnqGgZ"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x=\"xColName\", y=\"yColName\", data=df,palette=\"rainbow\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wi_mJa1qGga"
      },
      "source": [
        "## Sorted barplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEjszuVMqGga"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 15))\n",
        "#sort sns barplot \n",
        "#get the average saleprice per neighborhood \n",
        "perNei = df.groupby('Neighborhood').mean()['SalePrice'].sort_values(ascending=False)\n",
        "\n",
        "sns.barplot(x=perNei.index, y=perNei)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYAIneMvqGga"
      },
      "source": [
        "## SNS pairplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsKvhMO6qGga"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df, x_vars=colsList, y_vars=['Price'])\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIGxPY6XqGga"
      },
      "source": [
        "## Box plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXdxe0V9qGga"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "sns.boxplot(y='yColName', x='colName', data=df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGzfanTOqGga"
      },
      "outputs": [],
      "source": [
        "#pandas boxplots\n",
        "df[\"colName\"].plot.box(figsize=(8,8),color = 'blue')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctvYH1oMqGgb"
      },
      "source": [
        "## QQ plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKiwS6TNqGgb"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "\n",
        "def qq_plots(df):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    qqplot(df,line='s')\n",
        "    plt.title(\"Normal QQPlot\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUKw5smAqGgb"
      },
      "source": [
        "## Dist plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeOgQ14LqGgb"
      },
      "outputs": [],
      "source": [
        "sns.distplot(a=df['colName'])\n",
        "\n",
        "#optional: \n",
        "\n",
        "sns.distplot(a=df['colName'], bins=20, kde=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhZk0CrUqGgb"
      },
      "source": [
        "## Nice distripution plots for group of columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It9WBlOfqGgb"
      },
      "outputs": [],
      "source": [
        "def dist_custom(dataset, columns_list, rows, cols, suptitle, size=(16,20), y=0.92):\n",
        "    fig, axs = plt.subplots(rows, cols,figsize=size)\n",
        "    fig.suptitle(suptitle,y=y, size=16)\n",
        "    axs = axs.flatten() \n",
        "    for i, data in enumerate(columns_list):\n",
        "        mean, median = dataset[data].mean(), dataset[data].median()\n",
        "        graph = sns.histplot(dataset[data], ax=axs[i])\n",
        "        graph.axvline(mean, c='red',label='mean')\n",
        "        graph.axvline(median, c='green',label='median')\n",
        "        plt.legend()\n",
        "        axs[i].set_title(data + ', skew: '+str(round(dataset[data].skew(axis = 0, skipna = True),2)))\n",
        "        \n",
        "dist_custom(dataset=df, columns_list=numerical_Cols[:9], \n",
        "            rows=3, cols=3, suptitle='Distibution for each variable', size=(16,15), y=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84xoSMb5qGgb"
      },
      "source": [
        "## Logistic regression plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaC1xOcOqGgc"
      },
      "outputs": [],
      "source": [
        "sns.lmplot(x=\"xColName\", y=\"yColName\", data=df, logistic=True, y_jitter=.03)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUDyL5FjqGgc"
      },
      "source": [
        "## Scatter plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgNi8KdfqGgc"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='xColName', y='yColName', data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9uGCVR_qGgc"
      },
      "source": [
        "### Scatter plots with Hues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFnYQ_UnqGgc"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x=df['ColName'], y=df['colName2'], hue=df['HueColName'],palette=\"Set2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Iig_CSUqGgc"
      },
      "source": [
        "## 3D visualization (for clusters, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeUtSVlSqGgc"
      },
      "outputs": [],
      "source": [
        "def PlotCluster3D(dataframe, col):\n",
        "    fig = plt.figure(figsize=(10,8))\n",
        "    ax = plt.subplot(111, projection='3d', label=\"bla\")\n",
        "    x = dataframe['PCA1']\n",
        "    y = dataframe['PCA2']\n",
        "    z = dataframe['PCA3']\n",
        "    ax.scatter(x, y, z, s=40, c=dataframe[col], marker='o', cmap = 'viridis' )\n",
        "    ax.set_title(\"The Plot Of The Clusters {}\".format(col))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfmj1TVKqGgd"
      },
      "outputs": [],
      "source": [
        "PlotCluster3D(dataframe=df, col='KMeansColName')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2pu3hv4qGgd"
      },
      "source": [
        "# Skewness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UqDQ7ADqGgd"
      },
      "source": [
        "## Skewness calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W20zWHlqGgd"
      },
      "outputs": [],
      "source": [
        "df['colName'].agg(['skew', 'kurtosis']).transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gElf6MzRqGgd"
      },
      "source": [
        "## Box-Cox transformation for skewed columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvwsyAxSqGgd"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import boxcox\n",
        "\n",
        "# Box-Cox Transformation in Python\n",
        "df.insert(len(df.columns), 'colName_BoxCox',  boxcox(df.iloc[:, 0])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgVSYDBrqGgd"
      },
      "source": [
        "# Correlation analysis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-kjHVQ5qGge"
      },
      "outputs": [],
      "source": [
        "df.corr().style.background_gradient(cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZEdIITpqGge"
      },
      "source": [
        "## Heatmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC46vV6sqGge"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='YlGnBu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJHG3vlOqGge"
      },
      "source": [
        "## The point-Biserial result: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMosxLoiqGge"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "stats.pointbiserialr(df['colName1'], df['colName2'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ARmTF-VqGge"
      },
      "source": [
        "## Highly correlated variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ry_iqqyqGge"
      },
      "outputs": [],
      "source": [
        "upper_tri = df.corr().where(np.triu(np.ones(df.corr().shape),k=1).astype(np.bool))\n",
        "to_drop = [column for column in upper_tri.columns if any(abs(upper_tri[column]) > 0.70)]\n",
        "print(to_drop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQAuws7PqGgf"
      },
      "source": [
        "## sorted absolute correlation columns with target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p8W6aafqGgf"
      },
      "outputs": [],
      "source": [
        "x = df.corr()\n",
        "x = x['Target']\n",
        "sortedCorrelation = x.reindex(x.abs().sort_values().index)\n",
        "sortedCorrelation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw41D7p2qGgf"
      },
      "source": [
        "## Two correlation heat maps next to each other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTX8bp0BqGgf"
      },
      "outputs": [],
      "source": [
        "print(\"To the left, non-legendary\")\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5))\n",
        "attrib = ['hp','sp_attack','sp_defense','attack','defense','speed', 'base_happiness', 'capture_rate']\n",
        "sns.heatmap((df[df['is_legendary']==0][attrib]).corr(), annot=True, ax=ax1, cmap='coolwarm')\n",
        "sns.heatmap((df[df['is_legendary']==1][attrib]).corr(), annot=True, ax=ax2, cmap='coolwarm')\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkyh6Fh0qGgf"
      },
      "source": [
        "# Median values heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-qacbxdqGgf"
      },
      "outputs": [],
      "source": [
        "#understanding powers\n",
        "against = df.columns[df.columns.str.contains('against')]\n",
        "speciality = df.groupby(['type1']).median()[against]\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.heatmap(speciality, annot=True, cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz1mwZV_qGgf"
      },
      "source": [
        "## Variance threshold\n",
        "\n",
        "designed to drop columns with very low variance "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_JAxlPPqGgg"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "var_thr = VarianceThreshold(threshold = 0.10) #Removing both constant and quasi-constant\n",
        "var_thr.fit(df)\n",
        "\n",
        "var_thr.get_support()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puiR1crBqGgg"
      },
      "outputs": [],
      "source": [
        "concol = [column for column in df.columns \n",
        "          if column not in df.columns[var_thr.get_support()]]\n",
        "\n",
        "for features in concol:\n",
        "    print(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvlLnwsNqGgg"
      },
      "source": [
        "## get variance of all columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZoyUHc1qGgg"
      },
      "outputs": [],
      "source": [
        "numerical_Cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "for col in numerical_Cols.to_list():\n",
        "    print(col, \": \", df[col].var())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_EbK9ABqGgg"
      },
      "source": [
        "# Outliers analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60plYwZ5qGgg"
      },
      "source": [
        "## Hampel filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56cgX_-wqGgh"
      },
      "outputs": [],
      "source": [
        "def hampel(dfr, col, threshold):\n",
        "    med = dfr[col].median()\n",
        "    print(\"Median: \", med)\n",
        "    nullRows = dfr[dfr[col].isnull()]\n",
        "    mad =  np.nanmedian(np.abs(dfr[col] - np.nanmedian(dfr[col])))\n",
        "    print(\"MAD: \", mad)\n",
        "    print(\"Low range: \", med - threshold*1.4826*mad)\n",
        "    print(\"High range: \", med + threshold*1.4826*mad)\n",
        "    dfc = dfr.copy()\n",
        "    dfc = dfr[dfr[col]<(med + threshold*1.4826*mad)]\n",
        "    dfc = dfc[dfc[col]>(med - threshold*1.4826*mad)]\n",
        "    dfc = pd.merge(dfc, nullRows, how='outer')\n",
        "    print(\"Number of outliers: \", dfr.shape[0] - dfc.shape[0])\n",
        "    return dfc \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUZpOUFMqGgh"
      },
      "source": [
        "## IQR "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THJ-rkD5qGgh"
      },
      "outputs": [],
      "source": [
        "##IQR outliers \n",
        "\n",
        "def IQR_Outliers(dataframe, column, threshold):\n",
        "    Q1 = dataframe[column].quantile(0.25)\n",
        "    Q3 = dataframe[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - (IQR * threshold)\n",
        "    upper_bound = Q3 + (IQR * threshold)\n",
        "    print(\"Lower bound \", lower_bound, \"Upper bound: \", upper_bound)\n",
        "    return dataframe[(dataframe[column] < lower_bound) | (dataframe[column] > upper_bound)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Qb6fT-qGgh"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1Hq02LVqGgh"
      },
      "source": [
        "## Determining Number of clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MDFHdDhqGgi"
      },
      "source": [
        "### Elbow method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJO8Z3foqGgi"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "dist = []\n",
        "for i in range(1, 10):\n",
        "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 48484)\n",
        "    kmeans.fit(df)\n",
        "    dist.append(kmeans.inertia_)\n",
        "plt.plot(range(1, 10), dist,color = \"red\",marker = '*')\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RnxBlloqGgi"
      },
      "source": [
        "### The Silehoutte method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqI-JNn2qGgi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score \n",
        "\n",
        "def silhouette_scorer(dataframe, lowRange, highRange, title):\n",
        "    silhouette_scores = []\n",
        "    for i in range(lowRange, highRange):\n",
        "        m1=KMeans(n_clusters=i, random_state=42)\n",
        "        c = m1.fit_predict(dataframe)\n",
        "        silhouette_scores.append(silhouette_score(dataframe, m1.fit_predict(dataframe))) \n",
        "    plt.bar(range(2,10), silhouette_scores) \n",
        "    plt.xlabel(title, fontsize = 20) \n",
        "    plt.ylabel('S(i)', fontsize = 20) \n",
        "    plt.show()\n",
        "    return silhouette_scores\n",
        "\n",
        "scoresScaled = silhouette_scorer(df, 2, 10, \"scaled dataframe\")\n",
        "print(\"Scores Scaled: \", scoresScaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BbtSlWIqGgi"
      },
      "source": [
        "## Clustering algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg_n7hjDqGgi"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import MeanShift, KMeans, AffinityPropagation, SpectralClustering, AgglomerativeClustering, DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w62EzxMFqGgj"
      },
      "source": [
        "### Kmeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nlxj0weUqGgj"
      },
      "outputs": [],
      "source": [
        "def kmeansDF(nClusters, dataframe): \n",
        "    kmeans = KMeans(n_clusters=nClusters, random_state=42)\n",
        "    c = kmeans.fit_predict(dataframe)\n",
        "    return c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "806o5lCMqGgj"
      },
      "source": [
        "df['Kmeans'] = kmeansDF(4, df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjqNhecbqGgj"
      },
      "source": [
        "### Mean-Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ENJvk70qGgj"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import estimate_bandwidth\n",
        "def MeanShiftCluster(dataframe):\n",
        "    bandwidth = estimate_bandwidth(dataframe, quantile=0.2, n_samples=500)\n",
        "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
        "    ms.fit(dataframe)\n",
        "    return ms.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir9rW6ZoqGgj"
      },
      "outputs": [],
      "source": [
        "df['MeanShift'] = MeanShiftCluster(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCm3y0nnqGgj"
      },
      "source": [
        "### DBScan "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCitDz-UqGgk"
      },
      "outputs": [],
      "source": [
        "def DBScan(dataframe):\n",
        "    db = DBSCAN(eps=2000, min_samples=30).fit(dataframe)\n",
        "    return db.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr8WcaMXqGgk"
      },
      "outputs": [],
      "source": [
        "df['DBScan'] = DBScan(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBFvu3TTqGgk"
      },
      "source": [
        "### Affinity propagation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI_LPCQSqGgk"
      },
      "outputs": [],
      "source": [
        "def AffinityPropagationCluster(dataframe):\n",
        "    ap = AffinityPropagation(damping=0.95,preference=-1.0).fit(dataframe)\n",
        "    return ap.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8s9n3qFqGgk"
      },
      "outputs": [],
      "source": [
        "df['AffinityPropagation'] = AffinityPropagationCluster(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2J5PLZaqGgl"
      },
      "source": [
        "### Spectral clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a4BjT-lqGgl"
      },
      "outputs": [],
      "source": [
        "df['SpectralClustering'] = SpectralClustering(n_clusters=4, eigen_solver='arpack', affinity=\"nearest_neighbors\").fit_predict(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5kDPUgoqGgl"
      },
      "source": [
        "### Agglomerative clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCY-z831qGgl"
      },
      "outputs": [],
      "source": [
        "df['AgglomerativeClustering'] = AgglomerativeClustering(n_clusters=4, linkage='ward').fit_predict(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJgzZ5jKqGgl"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9LEaPZ4qGgl"
      },
      "source": [
        "# Dimensionality reduction "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a12khwxHqGgm"
      },
      "source": [
        "## PCA and number of components choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQw0rziFqGgm"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 0.99)\n",
        "pca.fit(df)\n",
        "reduced = pca.transform(df)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "xi = np.arange(1, 16, step=1)\n",
        "y = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "plt.ylim(0.0,1.1)\n",
        "plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
        "\n",
        "plt.xlabel('Number of Components')\n",
        "plt.xticks(np.arange(0, 17, step=1)) #change from 0-based array index to 1-based human-readable label\n",
        "plt.ylabel('Cumulative variance (%)')\n",
        "plt.title('The number of components needed to explain variance')\n",
        "\n",
        "plt.axhline(y=0.85, color='r', linestyle='-')\n",
        "plt.text(0.5, 0.85, '85% cut-off threshold', color = 'red', fontsize=16)\n",
        "\n",
        "ax.grid(axis='x')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HxgtauGqGgm"
      },
      "source": [
        "## PCA and rename new columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d209Rk4qGgm"
      },
      "outputs": [],
      "source": [
        "PCA_df = pd.DataFrame(reduced, index=df.index, columns=['PCA1', 'PCA2', 'PCA3', 'etc'])\n",
        "PCA_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExvJsSZ_qGgm"
      },
      "source": [
        "# Categorical encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWPPgsx2qGgn"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
        "def HandlingCategoricalFeatures(df):\n",
        "  #We need to check RegionName and CouncilArea with respect to the Price. \n",
        "  #Suburb has become ordinal numbers (ranking)\n",
        "  #check if there is any dependence between regionName and CouncilArea\n",
        "  cols = [ 'regionname','CouncilArea', 'Method', 'Type']\n",
        "\n",
        "  #Make them numbers first \n",
        "  le = OrdinalEncoder()\n",
        "  le.fit(df[cols])\n",
        "  df[cols] = le.transform(df[cols])\n",
        "  df[cols] = df[cols] + 1\n",
        "  for idx in cols:\n",
        "    for idx2 in cols: \n",
        "      if idx == idx2:\n",
        "        continue\n",
        "      else:\n",
        "        CrosstabResult=pd.crosstab(index=df[idx],columns=df[idx2])\n",
        "        print(CrosstabResult)\n",
        "        stat, p, dof, expected = chi2_contingency(CrosstabResult)\n",
        "        # interpret p-value\n",
        "        alpha = 0.05\n",
        "        print(\"p value is \" + str(p))\n",
        "        if p <= alpha:\n",
        "            print('Dependent (reject H0)')\n",
        "            #Check the strength of the correlation\n",
        "            val = [idx,idx2]\n",
        "            chisq_stat = stats.chi2_contingency(df[val], correction=False)[0]\n",
        "            # sample size\n",
        "            n = np.sum(np.sum(df[cols]))\n",
        "            # minimum of rows & columns\n",
        "            minshape = min(df[cols].shape)-1\n",
        "            # Cramer's v\n",
        "            V_ = np.sqrt( (chisq_stat/n)/minshape)\n",
        "            print(f\"Cramer' V: {V_}\")\n",
        "        else:\n",
        "            print('Independent (H0 holds true)')\n",
        "\n",
        "  #Plot each one alone\n",
        "  fig, axs = plt.subplots(2, 2, figsize = (15,10))\n",
        "  a = 0\n",
        "  b = 0\n",
        "  for i in cols: \n",
        "    sns.boxplot(ax = axs[a,b],x=i, y='Price', data=df)\n",
        "    if a >= 1:\n",
        "      a = 0\n",
        "      b = b + 1\n",
        "    elif a<=0:\n",
        "      a = a + 1\n",
        "  #Plot it with respect to the Price "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0JMjtraqGgn"
      },
      "source": [
        "# Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQN_LnBqqGgn"
      },
      "source": [
        "## changing categorical column of two values to binary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caSNdOaAqGgn"
      },
      "outputs": [],
      "source": [
        "df['_Gender'] = df['Gender'].eq('Male').mul(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih9LM54TqGgn"
      },
      "source": [
        "## Datetime conversion "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cibKmVSiqGgn"
      },
      "outputs": [],
      "source": [
        "df['Date'] = pd.to_datetime(df['Dt_String'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWyxK__MqGgo"
      },
      "source": [
        "## Ordinal encoding or categorical variables replacement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVZZVN2QqGgo"
      },
      "outputs": [],
      "source": [
        "replaceEDict = {'Graduation': \"Grad\", 'PhD': \"PostGrad\", 'Master': \"PostGrad\", 'Basic':\"UnderGrad\", '2n Cycle': \"PostGrad\"}\n",
        "\n",
        "df['Education'].replace(replaceEDict, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lfORIpWqGgo"
      },
      "outputs": [],
      "source": [
        "UtilDict = {'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1, 'None':0}\n",
        "df['_Utilities'] = df['Utilities'].map(UtilDict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfvLexWcqGgp"
      },
      "source": [
        "## Scaling and Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFdg_zA6qGgp"
      },
      "source": [
        "### Standard scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wB7rHHjqGgp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df)\n",
        "ScaledDF1 = scaler.transform(df)\n",
        "ScaledDF1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN7TDS2LqGgq"
      },
      "source": [
        "### Min-Max Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMZru6SAqGgq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df)\n",
        "ScaledDF1 = scaler.transform(df)\n",
        "ScaledDF1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jV4MjYDqGgq"
      },
      "source": [
        "## Label encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dNirkx3qGgq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "LabelEncoderM = LabelEncoder()\n",
        "df['colName'] = LabelEncoderM.fit_transform(df['colName'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgbnE9dTqGgq"
      },
      "source": [
        "## BaseN encoding (useful for grouping or encoding a large number of categroical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhi0rN7gqGgq"
      },
      "outputs": [],
      "source": [
        "#I will not one-hot encode all of these, let's try binary encoder\n",
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "\n",
        "#Create an object for Base N Encoding\n",
        "encoder= ce.BaseNEncoder(cols=['MSSubClass'],return_df=True,base=3)\n",
        "\n",
        "data_encoded=encoder.fit_transform(df)\n",
        "data_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8owjixJ8qGgr"
      },
      "source": [
        "# Modeling "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zju089RqqGgr"
      },
      "source": [
        "## Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz4xR1doqGgr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "Y = df['Target']\n",
        "X = df[colsList]\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-5E5SnHqGgr"
      },
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9zDNxHaqGgr"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(x_train, y_train)\n",
        "\n",
        "#get scores\n",
        "print(\"Training score without scaling: \", logisticRegr.score(x_train, y_train))\n",
        "print(\"Test score without scaling: \", logisticRegr.score(x_test, y_test))\n",
        "print('\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHd2qGJXqGgs"
      },
      "source": [
        "## Naive-Bayes \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AcVEECrqGgs"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "GaussianClassification = GaussianNB()\n",
        "GaussianClassification.fit(x_train, y_train)\n",
        "\n",
        "print(\"Training score: \", GaussianClassification.score(x_train, y_train))\n",
        "print(\"Testing score: \",GaussianClassification.score(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxlW_u2sqGgs"
      },
      "source": [
        "## SVM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsfP6fHRqGgs"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM = SVC(kernel='linear')\n",
        "#SVM = SVC(kernel='poly')\n",
        "#SVM = SVC(kernel='rbf')\n",
        "#SVM = SVC(kernel='sigmoid')\n",
        "\n",
        "\n",
        "SVM = SVM.fit(x_train, y_train)\n",
        "predictions = SVM.predict(x_test)\n",
        "\n",
        "print(\"Training score after scaling: \", SVM.score(x_train, y_train))\n",
        "print(\"Testing score after scaling: \",SVM.score(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrSzlG-UqGgs"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3GkbSniqGgs"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfm = RandomForestClassifier(max_depth=15, random_state=42, n_estimators=10)\n",
        "\n",
        "rfm = rfm.fit(x_train, y_train)\n",
        "predictions = rfm.predict(x_test)\n",
        "print(\"Training score after scaling: \", rfm.score(x_train, y_train))\n",
        "print(\"Testing score after scaling: \",rfm.score(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j--yzNjDqGgt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "predicted = rfm.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, predicted)\n",
        "print(f'Out-of-bag score estimate: {rfm.oob_score_:.3}')\n",
        "print(f'Mean accuracy score: {accuracy:.3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plVtXt78qGgt"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVqgLsfpqGgt"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "xg_reg = xgb.XGBClassifier(learning_rate = 0.1,\n",
        "                max_depth = 15, n_estimators = 20)\n",
        "\n",
        "xg_reg = xg_reg.fit(x_train, y_train)\n",
        "predictions = xg_reg.predict(x_test)\n",
        "print(\"Training score after scaling: \", xg_reg.score(x_train, y_train))\n",
        "print(\"Testing score after scaling: \",xg_reg.score(x_test, y_test))\n",
        "\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cross_val_score(XGBClassifier(), X, Y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4bI8M9AqGgt"
      },
      "source": [
        "### XGBoost feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7HipJm3qGgt"
      },
      "outputs": [],
      "source": [
        "print(xg_reg.feature_importances_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXFF_IqHqGgt"
      },
      "outputs": [],
      "source": [
        "from xgboost import plot_importance\n",
        "from matplotlib import pyplot\n",
        "plot_importance(xg_reg)\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIhtomrZqGgt"
      },
      "source": [
        "## AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv9w5ysKqGgu"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf = AdaBoostClassifier(n_estimators=100, random_state=43)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "predictions = clf.predict(x_test)\n",
        "print(\"Training score after scaling: \", clf.score(x_train, y_train))\n",
        "print(\"Testing score after scaling: \",clf.score(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgxJMckiqGgu"
      },
      "source": [
        "## KNN classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8gqdh-OqGgu"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=15)\n",
        "neigh.fit(x_train, y_train)\n",
        "\n",
        "predictions = neigh.predict(x_test)\n",
        "print(\"Training score after scaling: \", neigh.score(x_train, y_train))\n",
        "print(\"Testing score after scaling: \",neigh.score(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tricks\n"
      ],
      "metadata": {
        "id": "br49fbIqrFko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduce memory usage "
      ],
      "metadata": {
        "id": "8y47lMJKrHrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_memory_usage(df, verbose=True):\n",
        "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
        "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if (\n",
        "                    c_min > np.finfo(np.float16).min\n",
        "                    and c_max < np.finfo(np.float16).max\n",
        "                ):\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif (\n",
        "                    c_min > np.finfo(np.float32).min\n",
        "                    and c_max < np.finfo(np.float32).max\n",
        "                ):\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    if verbose:\n",
        "        print(\n",
        "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
        "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
        "            )\n",
        "        )\n",
        "    return df\n",
        "\n",
        "df = reduce_memory_usage(df, verbose=True)"
      ],
      "metadata": {
        "id": "hgWpQsy0rJEX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "My toolkit.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "g-KzAOB3qGgO",
        "_-_pi1CQqGgQ",
        "m41W_jcgqGgQ",
        "sbvdaf8MqGgR",
        "FeHy7yl5qGgR",
        "h2SotVozqGgS",
        "Y4v_6af3qGgS",
        "NyF7gQq6qGgT",
        "qRiVrpFbqGgT",
        "ZVw8pUK2qGgU",
        "NVbLtXStqGgV",
        "EDUL1gAoqGgW",
        "jS5EyR-wqGgX",
        "yt3mFRuNqGgX",
        "S7emJmyxqGgX",
        "1ikcGrGEqGgY",
        "aXQkhLfdqGgY",
        "uZYbcQ8MqGgY",
        "8sh7LBZjqGgY",
        "AZKD9aQhqGgZ",
        "B9IbU_rTqGgZ",
        "3wi_mJa1qGga",
        "IYAIneMvqGga",
        "NIGxPY6XqGga",
        "ctvYH1oMqGgb",
        "AUKw5smAqGgb",
        "JhZk0CrUqGgb",
        "84xoSMb5qGgb",
        "AUDyL5FjqGgc",
        "E9uGCVR_qGgc",
        "2Iig_CSUqGgc",
        "Y2pu3hv4qGgd",
        "1UqDQ7ADqGgd",
        "gElf6MzRqGgd",
        "MgVSYDBrqGgd",
        "HZEdIITpqGge",
        "bJHG3vlOqGge",
        "2ARmTF-VqGge",
        "GQAuws7PqGgf",
        "mw41D7p2qGgf",
        "Gkyh6Fh0qGgf",
        "cz1mwZV_qGgf",
        "nvlLnwsNqGgg",
        "t_EbK9ABqGgg",
        "60plYwZ5qGgg",
        "HUZpOUFMqGgh",
        "W4Qb6fT-qGgh",
        "j1Hq02LVqGgh",
        "0MDFHdDhqGgi",
        "-RnxBlloqGgi",
        "2BbtSlWIqGgi",
        "w62EzxMFqGgj",
        "IjqNhecbqGgj",
        "oCm3y0nnqGgj",
        "oBFvu3TTqGgk",
        "g2J5PLZaqGgl",
        "V5kDPUgoqGgl",
        "MJgzZ5jKqGgl",
        "m9LEaPZ4qGgl",
        "a12khwxHqGgm",
        "9HxgtauGqGgm",
        "ExvJsSZ_qGgm",
        "y0JMjtraqGgn",
        "jQN_LnBqqGgn",
        "ih9LM54TqGgn",
        "RWyxK__MqGgo",
        "WfvLexWcqGgp",
        "MFdg_zA6qGgp",
        "sN7TDS2LqGgq",
        "-jV4MjYDqGgq",
        "pgbnE9dTqGgq",
        "Zju089RqqGgr",
        "F-5E5SnHqGgr",
        "dHd2qGJXqGgs",
        "ZxlW_u2sqGgs",
        "nrSzlG-UqGgs",
        "plVtXt78qGgt",
        "r4bI8M9AqGgt",
        "bIhtomrZqGgt"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}